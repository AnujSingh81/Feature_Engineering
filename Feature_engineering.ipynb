{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1-What is a parameter?\n",
        "\n",
        "->A parameter is an internal configuration variable od a modal whose value is estimated(learned) during training"
      ],
      "metadata": {
        "id": "sASCUNKuMzVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-What is correlation?\n",
        "\n",
        "->correlation is a statistical measure that shows how strongly two variable are related to each other,that if one variable is changed how other changes"
      ],
      "metadata": {
        "id": "dRS9z_G1NhWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does negative correlation mean?\n",
        "\n",
        "->A negative correlation means that as one variable increases, the other decreaes and vice verse"
      ],
      "metadata": {
        "id": "nUjxWkQZOHN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "->Mechine learning is a branch of artifical intelligent that enables computers to learn pattern from data and make prediction or decicsion without being explicity progreammed\n",
        "\n",
        "main component of machine learning are Data,Model, Alogorithm"
      ],
      "metadata": {
        "id": "shPMNu0kOfm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "->The loss value tell us how well or poorly a model is perfroming.\n",
        "Lower loss=better prediction,but it should be low for both training and testing data"
      ],
      "metadata": {
        "id": "XOUWiA05PH30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-What are continuous and categorical variables?\n",
        "\n",
        "->A continous variable can take any numerical value within a range.these value are measureable and can include fractions or decimals.\n",
        "\n",
        "A categorical variable represents groups or categories.the values are labels (not numbers) and describe qualilites rather then quantities."
      ],
      "metadata": {
        "id": "EtebyyXNPvCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6-How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "->we convert categorical varibles in numbers before feeding them into model\n",
        "Common techniques which we use to handle categorical variable are Lebal Encoding,One-Hot encoding,Ordinal Encoding ,Count encoding,Target encoding,Binary encoding"
      ],
      "metadata": {
        "id": "hRunykG7SHq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-What do you mean by training and testing a dataset?\n",
        "\n",
        "->training dataset which we used to train our model and testing dataset which is used to test our model to measure in efficieny to predict"
      ],
      "metadata": {
        "id": "C5jYqEpzTewp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8-What is sklearn.preprocessing?\n",
        "\n",
        "->Sklearn.preprocessing is a module in scikit learn that provide tools to transform and prepare data before feeding it intp a machine learning model"
      ],
      "metadata": {
        "id": "0v13qUceT_K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9-What is a Test set?\n",
        "\n",
        "->A test set is a portin of your kept aisde data and not used during training. it is used after training to evaluate how well the model perfromd on unseen data"
      ],
      "metadata": {
        "id": "Ho9Jm_paUV1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "->in python we use a train test split module of sklearn.model_setection to split dataset into training and testing data,we define the testind data size in train test split as per our need"
      ],
      "metadata": {
        "id": "3ueMUHMGUz40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11-Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "->EDA is don e before model fitting to understand data,detect errors ,hsndle missing values and identify pattern or correlation. it ensures clean, accurate and meaningful data for training, without EDA, models may learn wrong patterns, leading to poor performance and unreliable prediction"
      ],
      "metadata": {
        "id": "YCfvjG8QVm6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12-What is correlation?\n",
        "\n",
        "->->correlation is a statistical measure that shows how strongly two variable are related to each other,that if one variable is changed how other changes"
      ],
      "metadata": {
        "id": "L3oPcCjBWpFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13-What does negative correlation mean?\n",
        "\n",
        "->A negative correlation means that as one variable increases, the other decreaes and vice verse"
      ],
      "metadata": {
        "id": "QGQkFLhkW99n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14-How can you find correlation between variables in Python?\n",
        "\n",
        "->to find correlation in python,we used a .corr modetd of pandas labriary"
      ],
      "metadata": {
        "id": "q80tkHQ1XIq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15-What is causation? Explain difference between correlation and causation with an example?\n",
        "\n",
        "-> Causation means that one variable directly affects or cause a change in another varible.\n",
        "\n",
        "main difference between causation and correlation is, in Correlation two variables move together (positive or negative) but one doesn't necessarily cause the other.eample: - ice cream sales and drowing bot increase in summer (due to heat) on the otherhand-causation ,one variable directly influence the other eample:- increased rainfall causes higher crop yield"
      ],
      "metadata": {
        "id": "V5fowpQuXtcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16-What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "->An optimizer is an algorithm that updates the model's parameters(weights and biases) to minimize the loss function and improve accuracy\n",
        "\n",
        "| Optimizer                                | Description                                                                               | Example Use                                                            |\n",
        "| ---------------------------------------- | ----------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n",
        "| **1. Gradient Descent (GD)**             | Updates weights using the gradient (slope) of the loss function.                          | Used in simple regression models.                                      |\n",
        "| **2. Stochastic Gradient Descent (SGD)** | Updates weights for each training example instead of the whole dataset, making it faster. | Common in large datasets and neural networks.                          |\n",
        "| **3. Mini-Batch Gradient Descent**       | Uses small batches of data (mix of GD and SGD) — more stable and efficient.               | Default approach in deep learning.                                     |\n",
        "| **4. Momentum**                          | Adds a fraction of the previous weight update to smooth the path towards the minimum.     | Helps avoid oscillations and speeds up convergence.                    |\n",
        "| **5. RMSProp**                           | Uses moving averages of squared gradients to adapt learning rates for each parameter.     | Works well for non-stationary objectives (e.g., RNNs).                 |\n",
        "| **6. Adam (Adaptive Moment Estimation)** | Combines Momentum + RMSProp. Adjusts learning rates automatically.                        | Most popular optimizer in deep learning (default in Keras/TensorFlow). |\n"
      ],
      "metadata": {
        "id": "DJanHKbUZcXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17-What is sklearn.linear_model?\n",
        "\n",
        "->Sklearn.linear_model is module in scikt-learn that provides classes and function for linear models- models that make predictions using a linear relationship between input feature and terget variable"
      ],
      "metadata": {
        "id": "EOzdsOx1aEx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18-What does model.fit() do? What arguments must be given?\n",
        "\n",
        "->model-fit() is the training function- its fits the model to the training data, meanin it learns the relationship betwwwn input features and target values,\n",
        "\n",
        "X and y arugment is given to model.fit()"
      ],
      "metadata": {
        "id": "1HZhiCjca3ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19-What does model.predict() do? What arguments must be given?\n",
        "\n",
        "->model.predict() is used after training a model to make prediction on new or unseen data\n",
        "\n",
        "X of test data argument is given for prediction"
      ],
      "metadata": {
        "id": "KJ9uiJKYbjML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20-What are continuous and categorical variables?\n",
        "\n",
        "->A continous variable can take any numerical value within a range.these value are measureable and can include fractions or decimals.\n",
        "\n",
        "A categorical variable represents groups or categories.the values are labels (not numbers) and describe qualilites rather then quantities."
      ],
      "metadata": {
        "id": "ohsvU3-VdBFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21-What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "->Feature Scaling is the process of normalizing or standardizing the range of independent variables (features) in your data so that they are on a similar scale.\n",
        "Feature Scaling is the process of normalizing or standardizing the range of independent variables (features) in your data so that they are on a similar scale."
      ],
      "metadata": {
        "id": "jFV1vCyncC0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22-How do we perform scaling in Python?\n",
        "\n",
        "->In Python, feature scaling is done using sklearn.preprocessing. Common methods include:\n",
        "\n",
        "StandardScaler() → scales data to mean 0, std 1\n",
        "\n",
        "MinMaxScaler() → scales data between 0 and 1"
      ],
      "metadata": {
        "id": "ZJSBSsCRcpM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23-What is sklearn.preprocessing?\n",
        "\n",
        "->Sklearn.preprocessing is a module in scikit learn that provide tools to transform and prepare data before feeding it intp a machine learning model"
      ],
      "metadata": {
        "id": "xcJu-zA0czvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24-How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "->in python we use a train test split module of sklearn.model_setection to split dataset into training and testing data,we define the testind data size in train test split as per our need"
      ],
      "metadata": {
        "id": "MU7HE0cbddd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25-Explain data encoding?\n",
        "\n",
        "->Data encoding is the process of converting categorical (non-numeric) data into a numeric format so that machine learning models can understand and process it."
      ],
      "metadata": {
        "id": "9JaR5xxmdoM1"
      }
    }
  ]
}